{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeplabv3  + Resnet101 CBAM_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.argv = ['-f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Namespace(GroupNorm=False, backbone='resnet101_CBAM', backbone_pretrained=None, base_size=1024, batch_size=2, checkname='resnet101_CBAM_1024_new_model_margin', crop_size=300, cuda=True, dataset='samsung_CAD_BE_1024_margin', epochs=5, eval_interval=5, freeze_bn=False, ft=True, gpu_ids=0, loss_type='mse', lr=0.001, lr_scheduler='poly', momentum=0.9, nesterov=False, no_cuda=False, no_val=False, optimizer='Adam', out_stride=16, resume=None, save_folder='E:/4_CAD_based_Hotspot_detection/Tensorboard_files/unsupervise', seed=999, start_epoch=0, sync_bn=None, test_batch_size=32, useCPU=False, use_balanced_weights=False, use_sbd=False, val_ref_path='E:/3_interdata/1009+1111+0927/0.generatedData/CAD', weight_decay=0.0005, workers=0)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"PyTorch DeeplabV3Plus Training\")\n",
    "parser.add_argument('--backbone', type=str, default='resnet',\n",
    "                    choices=['resnet', 'xception', 'drn', 'mobilenet'],\n",
    "                    help='backbone name (default: resnet)')\n",
    "parser.add_argument('--out-stride', type=int, default=16,\n",
    "                    help='network output stride (default: 8)')\n",
    "parser.add_argument('--dataset', type=str, default='samsung_SEM',\n",
    "                    choices=['pascal', 'coco', 'cityscapes','samsung_SEM','samsung_SEM_crop_256'],\n",
    "                    help='dataset name (default: pascal)')\n",
    "parser.add_argument('--use-sbd', action='store_true', default=False,\n",
    "                    help='whether to use SBD dataset (default: False)')\n",
    "parser.add_argument('--workers', type=int, default=0,\n",
    "\n",
    "                    metavar='N', help='dataloader threads')\n",
    "parser.add_argument('--base-size', type=int, default=1024,\n",
    "                    help='base image size')\n",
    "parser.add_argument('--crop-size', type=int, default=300,\n",
    "                    help='crop image size')\n",
    "parser.add_argument('--sync-bn', type=bool, default=None,\n",
    "                    help='whether to use sync bn (default: auto)')\n",
    "parser.add_argument('--freeze-bn', type=bool, default=False,\n",
    "                    help='whether to freeze bn parameters (default: False)')\n",
    "parser.add_argument('--loss-type', type=str, default='ce',\n",
    "                    choices=['ce', 'focal'],\n",
    "                    help='loss func type (default: ce)')\n",
    "# training hyper params\n",
    "parser.add_argument('--epochs', type=int, default=500, metavar='N',\n",
    "                    help='number of epochs to train (default: auto)')\n",
    "parser.add_argument('--start_epoch', type=int, default=0,\n",
    "                    metavar='N', help='start epochs (default:0)')\n",
    "parser.add_argument('--batch-size', type=int, default=16,\n",
    "                    metavar='N', help='input batch size for \\\n",
    "                            training (default: auto)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=32,\n",
    "                    metavar='N', help='input batch size for \\\n",
    "                            testing (default: auto)')\n",
    "parser.add_argument('--use-balanced-weights', action='store_true', default=False,\n",
    "                    help='whether to use balanced weights (default: False)')\n",
    "# optimizer params\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: auto)')\n",
    "parser.add_argument('--lr-scheduler', type=str, default='poly',\n",
    "                    choices=['poly', 'step', 'cos'],\n",
    "                    help='lr scheduler mode: (default: poly)')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    metavar='M', help='momentum (default: 0.9)')\n",
    "parser.add_argument('--weight-decay', type=float, default=5e-4,\n",
    "                    metavar='M', help='w-decay (default: 5e-4)')\n",
    "parser.add_argument('--nesterov', action='store_true', default=False,\n",
    "                    help='whether use nesterov (default: False)')\n",
    "# cuda, seed and logging\n",
    "parser.add_argument('--no-cuda', action='store_true', default=\n",
    "                    False, help='disables CUDA training')\n",
    "parser.add_argument('--gpu-ids', type=str, default='0',\n",
    "                    help='use which gpu to train, must be a \\\n",
    "                    comma-separated list of integers only (default=0)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "# checking point\n",
    "parser.add_argument('--resume', type=str, default=None,\n",
    "                    help='put the path to resuming file if needed')\n",
    "parser.add_argument('--checkname', type=str, default=None,\n",
    "                    help='set the checkpoint name')\n",
    "# finetuning pre-trained models\n",
    "parser.add_argument('--ft', action='store_true', default=False,\n",
    "                    help='finetuning on a different dataset')\n",
    "# evaluation option\n",
    "parser.add_argument('--eval-interval', type=int, default=1,\n",
    "                    help='evaluuation interval (default: 1)')\n",
    "parser.add_argument('--no-val', action='store_true', default=False,\n",
    "                    help='skip validation during training')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "args.backbone_pretrained = None\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "if args.cuda:\n",
    "    try:\n",
    "        args.gpu_ids = [int(s) for s in args.gpu_ids.split(',')]\n",
    "    except ValueError:\n",
    "        raise ValueError('Argument --gpu_ids must be a comma-separated list of integers only')\n",
    "        \n",
    "args.useCPU = False\n",
    "args.batch_size =2\n",
    "args.lr = 0.001\n",
    "#args.base_size = 400\n",
    "#args.crop_size = 400\n",
    "args.epochs = 5\n",
    "args.seed = 999\n",
    "args.out_stride = 16\n",
    "\n",
    "#args.dataset = 'samsung_CAD_BE_crop_256_NormalRatio_1'\n",
    "#args.dataset = 'samsung_CAD_BE_crop_512_NormalRatio_1'\n",
    "args.dataset = 'samsung_CAD_BE_1024_margin'\n",
    "\n",
    "args.checkname = 'resnet101_CBAM_1024_new_model_margin'\n",
    "#args.checkname = 'resnet101_CBAM_256_new_model'\n",
    "#args.checkname = 'resnet101_CBAM_512_new_model'\n",
    "\n",
    "args.backbone = 'resnet101_CBAM' #xception\n",
    "# args.backbone = 'resnet101'\n",
    "\n",
    "args.val_ref_path = 'E:/3_interdata/1009+1111+0927/0.generatedData/CAD'\n",
    "#args.val_ref_path = '/data2/0_Samsung_Data/3_Train_Data/Hotspot_prediction_using_CAD/DataSet_1_Size_1024x1024_margin/CAD+SEM_Images_with_box'\n",
    "#args.val_ref_path = '/data2/0_Samsung_Data/3_Train_Data/Hotspot_prediction_using_CAD/DataSet_1_Size_256x256_NormalRatio_1/CAD+SEM_Images_with_box'\n",
    "#args.val_ref_path = '/data2/0_Samsung_Data/3_Train_Data/Hotspot_prediction_using_CAD/DataSet_1_Size_512x512_NormalRatio_1/CAD+SEM_Images_with_box'\n",
    "\n",
    "args.GroupNorm = False\n",
    "args.loss_type = 'mse'\n",
    "\n",
    "args.save_folder ='E:/4_CAD_based_Hotspot_detection/Tensorboard_files/unsupervise'\n",
    "\n",
    "#args.backbone_pretrained = '/data2/2_ML_team/jaihoons/1_Research/99_Tensorboard_files/'\n",
    "#args.backbone_pretrained += '1_Classification/samsung_CAD_BE_crop_512_NormalRatio_1/resnet50_CBAM_512_NR_1/'\n",
    "#args.backbone_pretrained += 'model_best.pth'\n",
    "\n",
    "# args.resume = '/data2/2_ML_team/ml_ty/4_CAD_based_Hotspot_detection/3_Tensorboard_files/'\n",
    "# args.resume = 'E:/4_CAD_based_Hotspot_detection/Tensorboard_files/paper_iccad/samsung_CAD_BE_1024_margin/resnet101_CBAM_1024_new_model_margin/experiment_0/'\n",
    "# args.resume += 'checkpoint.pth.tar'\n",
    "\n",
    "#args.resume = '/data2/2_ML_team/jaihoons/1_Research/99_Tensorboard_files/'\n",
    "#args.resume += '2_Segmentation/samsung_CAD_BE_crop_256_NormalRatio_1/resnet50_CBAM_256_new_model/'\n",
    "#args.resume += 'model_best.pth.tar'\n",
    "\n",
    "#args.resume = '/data2/2_ML_team/jaihoons/1_Research/99_Tensorboard_files/'\n",
    "#args.resume += '1_Classification/samsung_CAD_BE_crop_512_NormalRatio_1/resnet50_CBAM_512_NR_1/'\n",
    "#args.resume += 'model_best.pth'\n",
    "\n",
    "#args.resume = '/data2/2_ML_team/jaihoons/1_Research/99_Tensorboard_files/'\n",
    "#args.resume += '2_Segmentation/samsung_CAD_BE_crop_256_NormalRatio_1/resnet50_CBAM_256/experiment_0/'\n",
    "#args.resume += 'checkpoint.pth.tar'\n",
    "\n",
    "#args.resume = '/data2/2_ML_team/jaihoons/1_Research/99_Tensorboard_files/\n",
    "#args.resume += '2_Segmentation/samsung_CAD_BE_crop_256_NormalRatio_1/resnet50_CBAM_256/experiment_0#args.resume += 'checkpoint.pth.tar'\n",
    "\n",
    "# args.resume = 'E:/4_CAD_based_Hotspot_detection/Tensorboard_files/'\n",
    "# args.resume += '1022+1030+1031/samsung_CAD_BE_1024_margin/resnet101_CBAM_1024_new_model_margin/'\n",
    "# args.resume += 'experiment_7/checkpoint.pth.tar'\n",
    "\n",
    "args.optimizer = 'Adam'\n",
    "args.gpu_ids = 0\n",
    "args.ft = True\n",
    "\n",
    "args.no_val = False\n",
    "args.eval_interval = 5\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorwatch as tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:37:18.815985Z",
     "start_time": "2019-12-02T04:37:18.764990Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import modeling.backbone.resnet_CBAM as resnet_CBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:37:20.244934Z",
     "start_time": "2019-12-02T04:37:19.652665Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "CBAM_model = resnet_CBAM.ResNet50(16, torch.nn.InstanceNorm2d, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:37:21.602238Z",
     "start_time": "2019-12-02T04:37:21.549164Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      )\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      )\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      )\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n      (bn2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      )\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n      (bn2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n      (bn2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (relu): ReLU(inplace=True)\n      (cbam): CBAM(\n        (SpatialGate): SpatialGate(\n          (compress): ChannelPool()\n          (spatial): BasicConv(\n            (conv1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (conv2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (conv3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n            (compress): ChannelPool()\n            (last_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n          )\n        )\n      )\n    )\n  )\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "CBAM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T07:10:48.090846Z",
     "start_time": "2019-11-23T07:10:30.076010Z"
    },
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-000071f677c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCBAM_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorwatch\\__init__.py\u001b[0m in \u001b[0;36mdraw_model\u001b[1;34m(model, input_shape, orientation, png_filename)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdraw_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'TB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpng_filename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#orientation = 'LR' for landscpe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmodel_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddenlayer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpytorch_draw_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpytorch_draw_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorwatch\\model_graph\\hiddenlayer\\pytorch_draw_model.py\u001b[0m in \u001b[0;36mdraw_graph\u001b[1;34m(model, args)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_img_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mDotWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorwatch\\model_graph\\hiddenlayer\\pytorch_draw_model.py\u001b[0m in \u001b[0;36mdraw_img_classifier\u001b[1;34m(model, dataset, display_param_nodes, rankdir, styles, input_shape)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mnon_para_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_non_parallel_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummaryGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_para_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msgraph2dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_param_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorwatch\\model_graph\\hiddenlayer\\summary_graph.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, dummy_input, apply_scope_name_workarounds)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mmodel_clone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverted_module_names_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_distiller_modulelist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_clone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_clone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_clone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.onnx' has no attribute 'set_training'"
     ],
     "ename": "AttributeError",
     "evalue": "module 'torch.onnx' has no attribute 'set_training'",
     "output_type": "error"
    }
   ],
   "source": [
    "tw.draw_model(CBAM_model,[1,3,512,512])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from dataloaders import make_data_loader\n",
    "kwargs = {'num_workers': args.workers, 'pin_memory': True}\n",
    "train_loader, val_loader, test_loader, nclass = make_data_loader(args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.figure(figsize=(25,5))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "sample = next(iter(train_loader))\n",
    "\n",
    "image,  insert_CAD ,target = sample['image'], sample['insert_CAD'], sample['label']\n",
    "image_name = sample['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "show(make_grid(image, padding=10, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "show(make_grid(insert_CAD, padding=10, normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "show(make_grid(target, padding=10, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "trainer = Trainer(args)\n",
    "print('Starting Epoch:', trainer.args.start_epoch)\n",
    "print('Total Epoches:', trainer.args.epochs)\n",
    "time.sleep(1)\n",
    "\n",
    "for epoch in range(trainer.args.start_epoch, trainer.args.epochs):\n",
    "    trainer.training(epoch)\n",
    "    if not trainer.args.no_val and epoch % args.eval_interval == (args.eval_interval - 1):\n",
    "        trainer.validation(epoch, val_ref_image_path=args.val_ref_path)\n",
    "trainer.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Validation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using device: cuda:0\n",
      "GPU CARD 0\n",
      "GeForce RTX 3080\n",
      "Memory Usage:\n",
      "Allocated: 1.1 GB\n",
      "Cached:    1.6 GB\n",
      "E:/5_weaklycontour/0_data/1_SamsungContour\n",
      "Number of images in train: 1900\n",
      "E:/5_weaklycontour/0_data/1_SamsungContour\n",
      "Number of images in test: 270\n",
      "Norm layer:  <class 'torch.nn.modules.instancenorm.InstanceNorm2d'>\n",
      "=> loaded checkpoint 'E:/4_CAD_based_Hotspot_detection/Tensorboard_files/1022+1030+1031/samsung_CAD_BE_1024_margin/resnet101_CBAM_1024_new_model_margin/experiment_7/checkpoint.pth.tar' (epoch 3)\n",
      "reset best pred..\n",
      "Starting Epoch: 0\n",
      "Total Epoches: 5\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\Sonic\\Anaconda3\\lib\\site-packages\\torch\\cuda\\memory.py:375: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  FutureWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='\\r'), FloatProgress(value=0.0, max=270.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78dc4c7df5c84ead8d083e2666f3420f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9e86df378e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m trainer.validation(0, use_data='test',\n\u001b[1;32m---> 24\u001b[1;33m                    val_ref_image_path= 'E:/3_interdata/1009+1111+0927/CAD')\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\4_CAD_based_Hotspot_detection\\DeepLab_v3plus_Pytorch_dist_CADlearning\\train.py\u001b[0m in \u001b[0;36mvalidation\u001b[1;34m(self, epoch, use_data, val_ref_image_path)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minsert_CAD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minsert_CAD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minsert_CAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samsung_SEM_BE'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samsung_CAD_BE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\4_CAD_based_Hotspot_detection\\DeepLab_v3plus_Pytorch_dist_CADlearning\\modeling\\deeplab.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, input_CAD)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_level_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maspp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_level_feat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_CAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bilinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\4_CAD_based_Hotspot_detection\\DeepLab_v3plus_Pytorch_dist_CADlearning\\modeling\\aspp.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maspp3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mx4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maspp4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mx5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_avg_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0mx5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bilinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\instancenorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     57\u001b[0m         return F.instance_norm(\n\u001b[0;32m     58\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             self.training or not self.track_running_stats, self.momentum, self.eps)\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36minstance_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[0;32m   2323\u001b[0m         )\n\u001b[0;32m   2324\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2325\u001b[1;33m         \u001b[0m_verify_spatial_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2326\u001b[0m     return torch.instance_norm(\n\u001b[0;32m   2327\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_verify_spatial_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2290\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2291\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2292\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected more than 1 spatial element when training, got input size {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 spatial element when training, got input size torch.Size([1, 256, 1, 1])"
     ],
     "ename": "ValueError",
     "evalue": "Expected more than 1 spatial element when training, got input size torch.Size([1, 256, 1, 1])",
     "output_type": "error"
    }
   ],
   "source": [
    "import time\n",
    "args.batch_size = 1\n",
    "args.dataset = 'samsung_CAD_BE_1024_margin'\n",
    "args.checkname = 'E:/4_CAD_based_Hotspot_detection/Tensorboard_files/Resnet50_Nonlocal_deeplab/samsung_CAD_BE_1024_margin/TEST3_samsung_deeplab_cad_heatmap_xception_800x800gpu_03'\n",
    "\n",
    "args.resume ='E:/4_CAD_based_Hotspot_detection/Tensorboard_files/1022+1030+1031/' \\\n",
    "             'samsung_CAD_BE_1024_margin/resnet101_CBAM_1024_new_model_margin/experiment_7/' \\\n",
    "            \n",
    "args.resume += 'checkpoint.pth.tar'\n",
    "# args.resume ='E:/4_CAD_based_Hotspot_detection/Tensorboard_files/paper_iccad/' \\\n",
    "#              'samsung_CAD_BE_1024_margin/resnet101_CBAM_1024_new_model_margin/'\n",
    "# args.resume += 'model_best.pth.tar'\n",
    "\n",
    "#args.resume = 'E:/4_CAD_based_Hotspot_detection/Tensorboard_files' \\\n",
    "#              '/1022+1030+1031/samsung_CAD_BE_1024_margin/resnet101_CBAM_1024_new_model_margin/experiment_7/checkpoint.pth.tar'\n",
    "args.GroupNorm = False\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "trainer = Trainer(args)\n",
    "print('Starting Epoch:', trainer.args.start_epoch)\n",
    "print('Total Epoches:', trainer.args.epochs)\n",
    "time.sleep(1)\n",
    "trainer.validation(0, use_data='test',\n",
    "                   val_ref_image_path= 'E:/3_interdata/1009+1111+0927/CAD')\n",
    "trainer.writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST or Inference ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:31:16.987792Z",
     "start_time": "2019-10-02T08:21:16.619752Z"
    },
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from test import *\n",
    "\n",
    "args.useCPU = False\n",
    "args.dataset = 'samsung_CAD_BE'\n",
    "args.batch_size = 10\n",
    "args.ft = True\n",
    "args.gpu_ids = 0\n",
    "args.start_epoch = 0\n",
    "args.epochs = 1\n",
    "args.seed = 1423\n",
    "args.backbone = 'xception'\n",
    "args.GroupNorm = True\n",
    "args.checkname = 'TEST_1k_samsung_deeplab_cad_heatmap_xception_800x800:gpu_00'\n",
    "\n",
    "args.resume = '/data/2_ML_team_data/jaihoons/1_SamsungProject/3_Tensor_Board_Files/2_Samsung_CAD/'\n",
    "args.resume += 'samsung_CAD_BE_crop_800/samsung_deeplab_cad_heatmap_xception_800x800:gpu_03/'\n",
    "args.resume += 'model_best.pth.tar'\n",
    "\n",
    "#CAD_image_dir = '/data/1_data/Samsung_Image_Data/blind_test_result/case2/CAD'\n",
    "#SEM_image_dir = '/data/1_data/Samsung_Image_Data/blind_test_result/case2/Image'\n",
    "\n",
    "CAD_image_dir = '/data/1_data/Samsung_Image_Data/images/blind_image_data_one_NEW/CAD'\n",
    "SEM_image_dir = '/data/1_data/Samsung_Image_Data/images/blind_image_data_one_NEW/CAD+Image'\n",
    "list_txt = '/data/1_data/Samsung_Image_Data/images/blind_image_data_one_NEW/test.txt'\n",
    "\n",
    "#CAD_image_dir = '/data/1_data/Samsung_Image_Data/images/blind_image_data_one_NEW_VOC_style_800x800/CAD_Images'\n",
    "#SEM_image_dir = '/data/1_data/Samsung_Image_Data/images/blind_image_data_one_NEW_VOC_style_800x800/CAD+SEM_Images_with_box'\n",
    "#list_txt = '/data/1_data/Samsung_Image_Data/images/blind_image_data_one_NEW_VOC_style_800x800/ImageSets/Main/test.txt'\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "tester = Tester(args, CAD_image_dir=CAD_image_dir, SEM_image_dir=SEM_image_dir,list_txt=list_txt, nclass=1)\n",
    "#-----------------------\n",
    "start_time = time.time()\n",
    "tester.test_batch(only_extract_result_img=True)\n",
    "tester.writer.close()\n",
    "end_time = time.time()\n",
    "#-----------------------\n",
    "print(\"Elaped Time: %s seconds\" % ( end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondaf82b03a23dbb4cb28940104fe6b74bfc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}